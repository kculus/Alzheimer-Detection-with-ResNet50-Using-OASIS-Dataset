{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5962731,"sourceType":"datasetVersion","datasetId":3419493}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:52:44.051142Z","iopub.execute_input":"2024-12-03T08:52:44.052058Z","iopub.status.idle":"2024-12-03T08:53:07.140964Z","shell.execute_reply.started":"2024-12-03T08:52:44.052022Z","shell.execute_reply":"2024-12-03T08:53:07.139916Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Importing Necessary Libraries","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models, transforms\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom torchvision.models import resnet50, ResNet50_Weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:53:07.142624Z","iopub.execute_input":"2024-12-03T08:53:07.142923Z","iopub.status.idle":"2024-12-03T08:53:07.147928Z","shell.execute_reply.started":"2024-12-03T08:53:07.142897Z","shell.execute_reply":"2024-12-03T08:53:07.147044Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Dataset Loading and Splitting","metadata":{}},{"cell_type":"code","source":"data_dir = \"/kaggle/input/imagesoasis/Data\"  # Original Dataset\nclasses = [\"Mild Dementia\", \"Moderate Dementia\", \"Non Demented\", \"Very mild Dementia\"]\n\nall_data = []\nall_labels = []\n\nfor idx, class_name in enumerate(classes):\n    class_dir = os.path.join(data_dir, class_name)\n    for file_name in os.listdir(class_dir):\n        if file_name.endswith(\".jpg\") or file_name.endswith(\".png\"):\n            all_data.append(os.path.join(class_dir, file_name))\n            all_labels.append(idx)\n\n\ntrain_data, val_data, train_labels, val_labels = train_test_split(\n    all_data, all_labels, test_size=0.2, random_state=42, stratify=all_labels\n)\n\nprint(f\"Train size: {len(train_data)}, Validation size: {len(val_data)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:53:07.148990Z","iopub.execute_input":"2024-12-03T08:53:07.149253Z","iopub.status.idle":"2024-12-03T08:53:07.349750Z","shell.execute_reply.started":"2024-12-03T08:53:07.149228Z","shell.execute_reply":"2024-12-03T08:53:07.348858Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Class Weights Calculation","metadata":{}},{"cell_type":"code","source":"class_counts = [train_labels.count(idx) for idx in range(len(classes))]\nclass_weights = [1.0 / count for count in class_counts]\nclass_weights = torch.tensor(class_weights).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Class counts: {class_counts}\")\nprint(f\"Class weights: {class_weights}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:53:07.352229Z","iopub.execute_input":"2024-12-03T08:53:07.352811Z","iopub.status.idle":"2024-12-03T08:53:07.637153Z","shell.execute_reply.started":"2024-12-03T08:53:07.352781Z","shell.execute_reply":"2024-12-03T08:53:07.636171Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### DementiaDataset Class\r\n- **Purpose**: Custom dataset class for loading image data and labels.\r\n\r\n#### Methods:\r\n1. **`__init__`**:\r\n   - Initializes the dataset with image paths (`data`), labels (`labels`), and optional transformations (`transform`).\r\n\r\n2. **`__len__`**:\r\n   - Returns the total number of samples in the dataset.\r\n\r\n3. **`__getitem__`**:\r\n   - Fetches an image and its corresponding label based on the index (`idx`).\r\n   - Applies the specified transformations to the image if provided.\r\n   - Returns the processed image and its label.\r\n","metadata":{}},{"cell_type":"code","source":"class DementiaDataset(Dataset):\n    def __init__(self, data, labels, transform=None):\n        self.data = data\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path = self.data[idx]\n        label = self.labels[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n\n\ntransform = transforms.Compose([\n    transforms.Resize((496, 248)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\ntrain_dataset = DementiaDataset(train_data, train_labels, transform=transform)\nval_dataset = DementiaDataset(val_data, val_labels, transform=transform)\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:53:07.638142Z","iopub.execute_input":"2024-12-03T08:53:07.638417Z","iopub.status.idle":"2024-12-03T08:53:07.645889Z","shell.execute_reply.started":"2024-12-03T08:53:07.638385Z","shell.execute_reply":"2024-12-03T08:53:07.645019Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model Initialization and Configuration","metadata":{}},{"cell_type":"code","source":"weights = ResNet50_Weights.IMAGENET1K_V1\nresnet_model = resnet50(weights=weights)\nnum_classes = len(classes)\nin_features = resnet_model.fc.in_features\nresnet_model.fc = nn.Linear(in_features, num_classes)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nresnet_model = resnet_model.to(device)\n\n\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\noptimizer = torch.optim.Adam(resnet_model.parameters(), lr=0.001)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:53:07.646987Z","iopub.execute_input":"2024-12-03T08:53:07.647251Z","iopub.status.idle":"2024-12-03T08:53:08.239802Z","shell.execute_reply.started":"2024-12-03T08:53:07.647225Z","shell.execute_reply":"2024-12-03T08:53:08.238749Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model Training and Validation","metadata":{}},{"cell_type":"code","source":"num_epochs = 10\nsave_model_path = \"/kaggle/working/resnet_alzheimer_final.pth\"  \n\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    \n    # Train\n    resnet_model.train()\n    train_loss = 0.0\n    for images, labels in tqdm(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = resnet_model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n    \n    avg_train_loss = train_loss / len(train_loader)\n    \n    # Validation\n    resnet_model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = resnet_model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            \n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    avg_val_loss = val_loss / len(val_loader)\n    accuracy = 100 * correct / total\n    \n    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {accuracy:.2f}%\")\n    \n    # Saving the model\n    if epoch == num_epochs - 1:\n        torch.save(resnet_model.state_dict(), save_model_path)\n        print(f\"Model saved at last epoch: {save_model_path}\")\n\nprint(\"Eğitim Tamamlandı!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:53:08.241074Z","iopub.execute_input":"2024-12-03T08:53:08.241378Z","iopub.status.idle":"2024-12-03T11:34:55.589658Z","shell.execute_reply.started":"2024-12-03T08:53:08.241351Z","shell.execute_reply":"2024-12-03T11:34:55.588538Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model Prediction and Visualization","metadata":{}},{"cell_type":"code","source":"model_path = \"/kaggle/working/resnet_alzheimer_final.pth\"\nweights = ResNet50_Weights.IMAGENET1K_V1\nresnet_model = resnet50(weights=weights)\nnum_classes = 4\nin_features = resnet_model.fc.in_features\nresnet_model.fc = nn.Linear(in_features, num_classes)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nresnet_model.load_state_dict(torch.load(model_path, map_location=device))\nresnet_model = resnet_model.to(device)\nresnet_model.eval()\n\n# Image transforms\ntransform = transforms.Compose([\n    transforms.Resize((496, 248)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\n# Class names\nclasses = [\"Mild Dementia\", \"Moderate Dementia\", \"Non Demented\", \"Very mild Dementia\"]\n\n\nimage_paths = {\n    \"Mild Dementia\": \"/kaggle/input/imagesoasis/Data/Mild Dementia/OAS1_0031_MR1_mpr-3_147.jpg\",\n    \"Moderate Dementia\": \"/kaggle/input/imagesoasis/Data/Moderate Dementia/OAS1_0308_MR1_mpr-2_132.jpg\",\n    \"Non Demented\": \"/kaggle/input/imagesoasis/Data/Non Demented/OAS1_0379_MR2_mpr-2_112.jpg\",\n    \"Very mild Dementia\": \"/kaggle/input/imagesoasis/Data/Very mild Dementia/OAS1_0142_MR1_mpr-3_129.jpg\"\n}\n\n\nfig, axes = plt.subplots(1, len(classes), figsize=(20, 5))\n\nfor idx, (class_name, image_path) in enumerate(image_paths.items()):\n    \n    image = Image.open(image_path).convert(\"RGB\")\n    input_image = transform(image).unsqueeze(0).to(device)\n    \n    \n    with torch.no_grad():\n        outputs = resnet_model(input_image)\n        _, predicted_class = torch.max(outputs, 1)\n    \n    \n    predicted_label = classes[predicted_class.item()]\n    \n    \n    axes[idx].imshow(image)\n    axes[idx].set_title(f\"Original: {class_name}\\nPredict: {predicted_label}\")\n    axes[idx].axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T11:36:32.390072Z","iopub.execute_input":"2024-12-03T11:36:32.390439Z","iopub.status.idle":"2024-12-03T11:36:33.541881Z","shell.execute_reply.started":"2024-12-03T11:36:32.390407Z","shell.execute_reply":"2024-12-03T11:36:33.541035Z"}},"outputs":[],"execution_count":null}]}